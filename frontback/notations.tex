% Notations ====================================================================

\chapter{Notations}

\begin{tabularx}{\textwidth}{ l X }
${\cal A}$ & A supervised learning algorithm \dotfill  \pageref{ntn:A}\\
${\cal A}(\theta, {\cal L})$ & The model $\varphi_{\cal L}$ produced by algorithm ${\cal A}$ over ${\cal L}$ and hyper-parameters $\theta$ \dotfill  \pageref{ntn:A-func}\\
$b_l$ & The $l$-th value of a categorical variable \dotfill  \pageref{ntn:b_l}\\
$c_k$ & The $k$-th class \dotfill  \pageref{ntn:c_k}\\
$\overline{E}(\varphi_{\cal L}, {\cal L}^\prime)$ & The average prediction error of $\varphi_{\cal L}$ over ${\cal L}^\prime$ \dotfill  \pageref{ntn:E_bar}\\
$Err(\varphi_{\cal L})$ & The generalization error of $\varphi_{\cal L}$ \dotfill  \pageref{ntn:err}\\
$\widehat{Err}^\text{train}(\varphi_{\cal L})$ & The resubstitution estimate or training sample estimate of the generalization error of $\varphi_{\cal L}$ \dotfill  \pageref{ntn:err-train}\\
$\widehat{Err}^\text{test}(\varphi_{\cal L})$ & The test sample estimate of the generalization error of $\varphi_{\cal L}$ \dotfill  \pageref{ntn:err-test}\\
$\widehat{Err}^\text{CV}(\varphi_{\cal L})$ & The cross-validation  estimate of the generalization error of $\varphi_{\cal L}$ \dotfill  \pageref{ntn:err-cv}\\
${\cal H}$ & The space of candidate models \dotfill  \pageref{ntn:H}\\
$i(t)$ & The impurity of node $t$ \dotfill  \pageref{ntn:i_t}, \pageref{ntn:i_t2}\\
$i_R(t)$ & The impurity of node $t$ based on the local resubstitution estimate \dotfill \pageref{ntn:i_t_R},~\pageref{eqn:impurity:variance}\\
$i_H(t)$ & The entropy impurity of node $t$ \dotfill  \pageref{eqn:impurity:shannon}\\
$i_G(t)$ & The Gini impurity of node $t$ \dotfill  \pageref{eqn:impurity:gini}\\
$\Delta i(s, t)$ & The impurity decrease of the split $s$ at node $t$ \dotfill  \pageref{ntn:delta-i_t}\\
$J$ & The number of classes \dotfill  \pageref{ntn:J}\\
$K$ & The number of folds in cross-validation \dotfill  \pageref{ntn:K-cv}\\
$K(\mathbf{x}_i, \mathbf{x}_j)$ & The kernel of $\mathbf{x}_i$ and $\mathbf{x}_j$ \dotfill \pageref{ntn:kernel}, \pageref{ntn:kernel2}\\
$L$ & A loss function \dotfill  \pageref{ntn:L}\newline The number of values of a categorical variable \dotfill \pageref{ntn:L2}\\
${\cal L}$ & A learning set $(\mathbf{X}, \mathbf{y})$ \dotfill  \pageref{ntn:learning-set}\\
${\cal L}_t$ & The subset of node samples falling into node $t$ \dotfill  \pageref{ntn:L_t}\\
$N$ & The number of input samples \dotfill  \pageref{ntn:N}\\
$N_t$ & The number of node samples in node $t$ \dotfill  \pageref{ntn:N_t}\\
$N_{ct}$ & The number of node samples of class $c$ in node $t$ \dotfill  \pageref{ntn:N_ct}\\
$\Omega$ & The universe, or population, from which cases are sampled \dotfill  \pageref{ntn:omega}\\
$p$ & The number of input variables \dotfill  \pageref{ntn:p}\\
$p_L$ & The proportion of node samples going to $t_L$ \dotfill  \pageref{ntn:p_L}\\
$p_R$ & The proportion of node samples going to $t_R$ \dotfill  \pageref{ntn:p_R}\\
$p(t)$ & The estimated probability $p(X \in {\cal X}_t)=\tfrac{N_t}{N}$ \dotfill  \pageref{ntn:p_t}\\
$p(c|t)$ & The estimated probability $p(Y=c | X \in {\cal X}_t)=\tfrac{N_{ct}}{N_t}$ of class $c$ at node $t$ \dotfill  \pageref{ntn:p_ct}\\
$P(X,Y)$ & The joint probability distribution of the input variables $X=(X_1,\dots,X_p)$ and the output variable $Y$ \dotfill  \pageref{ntn:P_XY}\\
$\varphi$ & A model or function ${\cal X} \mapsto {\cal Y}$ \dotfill  \pageref{ntn:varphi}\newline A single decision tree \dotfill  \pageref{ntn:tree}\\
$\widetilde{\varphi}$ & The set of terminal nodes in $\varphi$ \dotfill  \pageref{ntn:varphi-leafs}\\
$\varphi(\mathbf{x})$ & The prediction of $\varphi$ for the sample $\mathbf{x}$ \dotfill  \pageref{ntn:varphi-x}\\
$\varphi_{\cal L}$ & A model built from ${\cal L}$ \dotfill  \pageref{ntn:varphi-L}\\
$\varphi_B$ & A Bayes model \dotfill  \pageref{ntn:varphi-B}\\
${\cal Q}$ & A set ${\cal Q} \subseteq {\cal S}$ of splits of restricted structure \dotfill \pageref{ntn:Q}, \pageref{ntn:Q2}\\
${\cal Q}(X_j)$ & The set ${\cal Q}(X_j) \subseteq {\cal Q}$ of univariate binary splits that can be defined on variable $X_j$ \dotfill \pageref{ntn:Q_X_j}, \pageref{ntn:Q_X_j2}\\
$s$ & A split \dotfill  \pageref{ntn:s}, \pageref{ntn:s2}\\
$s^*$ & The best split \dotfill  \pageref{ntn:s-star}, \pageref{ntn:s-star2}\\
$s^*_j$ & The best binary split defined on variable $X_j$\dotfill  \pageref{ntn:s-star}, \pageref{ntn:s-star_j}\\
$s_j^v$ & The binary split $(\{\mathbf{x}|x_j \leq v\}, \{\mathbf{x} > v\})$ defined on variable $X_j$ with discretization threshold $v$ \dotfill  \pageref{ntn:s_jv}\\
$s_t$ & The split labeling node $t$ \dotfill  \pageref{ntn:s_t}\\
${\cal S}$ & The set of all possible splits $s$ \dotfill  \pageref{ntn:S-all}\\
$t$ & A node in a decision tree \dotfill  \pageref{ntn:node}\\
$t_L$ & The left child of node $t$ \dotfill \pageref{ntn:t_L}, \pageref{ntn:t_L2}\\
$t_R$ & The right child of node $t$ \dotfill \pageref{ntn:t_R}, \pageref{ntn:t_R2}\\
$\theta$ & A vector of hyper-parameter values \dotfill  \pageref{ntn:theta}\\
$\theta^*$ & The optimal hyper-parameters \dotfill  \pageref{ntn:theta-star}\\
$\widehat{\theta}^*$ & The approximately optimal hyper-parameters \dotfill  \pageref{ntn:theta-star-approx}\\
$v$ & A discretization threshold in a binary split \dotfill  \pageref{ntn:v}\\
$v_k$ & The $k$-th value of an ordered variable, when node samples are in sorted order \dotfill  \pageref{ntn:v_k}\\
$v_k^\prime$ & The mid-cut point between $v_k$ and $v_{k+1}$ \dotfill  \pageref{ntn:v_k_prime}\\
$\textbf{x}$ & A case, sample or input vector $(x_1, \dots, x_p)$ \dotfill  \pageref{ntn:sample-x}\\
$\textbf{x}_i$ & The $i$-th input sample in ${\cal L}$ \dotfill  \pageref{ntn:sample-x_i}\\
$x_j$ & The value of variable $X_j$ for the sample $\textbf{x}$ \dotfill  \pageref{ntn:value-x_j}\\
$\textbf{X}$ & The $N\times p$ matrix representing the values of all $N$ samples for all $p$ input variables \dotfill  \pageref{ntn:matrix-X}\\
$X_j$ & The $j$-th input variable or feature \dotfill  \pageref{ntn:var-X_j}, \pageref{ntn:var-X_j2}\\
$X$ & The random vector $(X_1,\dots,X_p)$ \dotfill  \pageref{ntn:vector-X}\\
${\cal X}_j$ & The domain or space of variable $X_j$ \dotfill  \pageref{ntn:space-X_j}\\
${\cal X}$ & The input space ${\cal X}_1 \times \dots \times {\cal X}_p$ \dotfill  \pageref{ntn:space-X}\\
${\cal X}_t$ & The subspace ${\cal X}_t \subseteq {\cal X}$ represented by node $t$ \dotfill  \pageref{ntn:node-space}\\
$y$ & A value of the ouput variable $Y$ \dotfill  \pageref{ntn:value-y}\\
$\widehat{y}_t$ & The value labelling node $t$ \dotfill  \pageref{ntn:y_t}\\
$\widehat{y}_t^*$ & The optimal value labelling node $t$ \dotfill  \pageref{ntn:y_t-star}\\
$\mathbf{y}$ & The output values $(y_1,\dots,y_N)$ \dotfill  \pageref{ntn:vector-y}\\
$Y$ & The output or response variable $Y$ \dotfill  \pageref{ntn:var-Y}\\
${\cal Y}$ & The domain or space of variable $Y$ \dotfill  \pageref{ntn:space-Y}\\
\end{tabularx}
