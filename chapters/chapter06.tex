\chapter{Variable importances}\label{ch:importances}

\begin{remark}{Outline}
This chapter studies variable importance measures as computed from forests of
randomized trees. In Section~\ref{sec:6:importances}, we first present how
random forests can be used to assess the importance of input variables.  We
then derive in Section~\ref{sec:6:theory} a characterization in asymptotic
conditions and show that variable importances derived from totally randomized trees
offer a three-level decomposition of the information jointly  contained in the
input variables about the output. In Section~\ref{sec:6:variable-relevance}, we
show that this  characterization only depends on the relevant variables and
then discuss these ideas in Section~\ref{sec:6:variants} in the context of
variants closer to the Random Forest algorithm. Finally, we illustrate these
results on an artifical problem in Section~\ref{sec:6:illustration}.
\end{remark}

An important task in many scientific fields is the prediction of  a response
variable based on a set of predictor variables. In many situations though, the
aim is not only to make the most accurate predictions of the response but also
to identify which predictor variables are the most important to make these
predictions, e.g. in order to understand the underlying process. Because of
their applicability to a wide range of problems and their capability to both
build accurate models and, at the same time, to provide variable importance
measures, random forests have become a major data analysis tool used with
success in various scientific areas.

Despite their extensive use in applied research, only a couple of works have
studied the theoretical properties and statistical mechanisms of these
algorithms. \citet{zhao:2000}, \citet{breiman:2004},
\citet{biau:2008,biau:2012}, \citet{meinshausen:2006} and \citet{lin:2006}
investigated simplified to very realistic variants of these algorithms and
proved  the consistency of those variants. Little is known however regarding
the variable importances computed by random forests, and -- as far as we know
-- the work of~\citet{ishwaran:2007} is indeed the only theoretical study of
tree-based variable importance measures. In this chapter, we aim at filling
this gap and present a theoretical  analysis of the Mean Decrease Impurity
importance derived from ensembles of randomized trees.

\textit{The content of this chapter is based on previous work published in \citep{louppe:2013}.}

% A forest of trees is impenetrable
% as far as simple interpretations of its mechanims go~\citep{breiman:2001}.


\section{Variable importances}
\label{sec:6:importances}

\subsection{Importances in single decision trees}

In the context of single decision trees, \cite{breiman:1984} first defined
the measure of importance of a variable $X_j$ as
\begin{equation}
\text{Imp}(X_j) = \sum_{t\in \varphi} \Delta I(\tilde{s}^j_t, t),
\end{equation}
where $\tilde{s}^j_t$ is the best surrogate split
for $s_t$ -- that is the best split using variable $X_j$ to predict the actual
split $s_t$ defined at node $t$. The use of surrogate splits was proposed to
account for masking effects: it may indeed happen that some variable $X_{j_2}$
never occurs in any split because it leads to splits that are slightly worse,
and therefore not selected, than those of some other variable $X_{j_1}$.
However, if $X_{j_1}$ is removed and another tree is grown, $X_{j_2}$ may now
occur prominently within the splits and the resulting tree may be nearly as good
as the original tree. In such a case, a relevant measure should detect the
importance of $X_{j_2}$. Accordingly, if $X_{j_2}$ is being masked at $t$ by
$X_{j_1}$ (i.e., if $X_{j_1}$ is used to split $t$), but if $\tilde{s}^{j_2}_t$ is similar to
$s_t$, but not quite as good, then $\Delta I(\tilde{s}^{j_2}_t, t)$ will be
nearly as large as $\Delta I(s_t, t)$ and therefore the proposed measure will
indeed account for the importance of $X_{j_2}$.

Thanks to randomization, masking effects are dampened within forests of
randomized trees. Even if $X_{j_2}$ is being masked by $X_{j_1}$ there is indeed
still a chance for $X_{j_2}$ to be chosen as a split if $X_{j_1}$ is not
selected among the $K$ variables chosen at random. Depending on the value $K$,
masking effects do not disappear entirely though. The use of bootstrap samples
also helps reduce masking effects, making $X_{j_1}$ or $X_{j_2}$ just slightly
better than the other due to the variations in the bootstrap samples.

\subsection{Importances in forests}

In the context of ensembles of randomized trees,
\cite{breiman:2001,breiman:2002} proposed to evaluate the importance of
a variable $X_j$  for predicting  $Y$ by adding up the weighted impurity decreases $p(t) \Delta
i(s_t, t)$ for all nodes $t$ where $X_j$ is used, averaged over all trees $\varphi_m$ (for $m=1,\dots,M$)
in the forest:
\begin{equation}\label{eq:mdi}
\text{Imp}(X_j) = \frac{1}{M} \sum_{m=1}^M \sum_{t \in \varphi_{m}} 1(X_{s_t} = X_j) \Big[ p(t) \Delta i(s_t, t) \Big],
\end{equation}
where $p(t)$ is the proportion $\tfrac{N_t}{N}$ of samples
reaching $t$ and where $X_{s_t}$ denotes the variable used in split $s_t$. When
using the Gini index as impurity function, this measure is known as the
\textit{Gini importance} or \textit{Mean Decrease Gini}. However, since it can
be defined for any impurity measure $i(t)$, we will refer to Equation~\ref{eq:mdi}
as the \textit{Mean Decrease Impurity} importance (MDI), no matter the impurity
measure $i(t)$. We will characterize and derive results for this measure in the
rest of this text.

In addition to MDI, \cite{breiman:2001,breiman:2002} also proposed to evaluate
the importance of a variable $X_j$ by measuring the \textit{Mean Decrease
Accuracy} (MDA) of the forest when the values of $X_j$ are randomly permuted in
the out-of-bag samples or in an independent test set. For that reason, this
latter measure is also known as the \textit{permutation importance}.
% It is
% formally given by the following equation:
% \begin{equation}\label{eq:mdi}
% \text{Imp}(X_j) = \frac{1}{M} \sum_{m=1}^M \sum_{t \in \varphi_{m}} 1(X_{s_t} = X_j) \Big[ p(t) \Delta i(s_t, t) \Big],
% \end{equation}

Thanks to popular machine learning
softwares~\citep{breiman:2002,liaw:2002,pedregosa:2011},
both of these variable importance measures have shown their practical utility in
an increasing number of experimental studies. Little is known however regarding
their inner workings. \cite{strobl:2007b} compare both MDI and MDA and show
experimentally that the former is biased towards some predictor variables. As
explained by~\cite{white:1994} in case of single decision trees, this
bias stems from an unfair advantage given by the usual impurity functions $i(t)$
towards predictors with a large number of values. \cite{strobl:2008}
later showed  that MDA is biased as well, and that it overestimates the
importance of correlated variables -- although this effect was not confirmed in
a later experimental study by~\cite{genuer:2010}.  From a theoretical
point of view, \cite{ishwaran:2007} provides a detailed theoretical
development of a simplified version of MDA, giving key insights for the
understanding of the actual MDA.

\section{Theoretical study}
\label{sec:6:theory}


\section{Relevance of variables}
\label{sec:6:variable-relevance}


\section{Variable importances in random forest variants}
\label{sec:6:variants}


\section{Illustration}
\label{sec:6:illustration}

