\chapter{Background}\label{ch:background}

\section{Learning from data}

In the examples introduced in Chapter~\ref{ch:introduction}, the objective
which is sought is to find a systematic way of predicting a phenomenon given a
set of measurements. In machine learning terms, this goal is formulated as the
{\it supervised learning} task of infering from collected data a model that
predicts the value of an output variable based on the observed values of input
variables. In medicine for instance, the goal is to find a decision rule (i.e.,
a model) from a set of past cases (i.e., the collected data) for predicting the
condition of an incoming patient (i.e., the output value) given a set of
measurements such as age, sex, blood pressure or history (i.e., the input
values).

To give a more precise formulation, let us arrange the set of measurements on a
case in a pre-assigned order, i.e., take the input values to be $x_1, x_2, ...,
x_p$, where $x_j \in {\cal X}_j$ (for $j = 1, ..., p$) corresponds to the value
of the input variable $X_j$. Together, the input values $(x_1, x_2, ..., x_p)$
form a $p$-dimensional input vector $\mathbf{x}$ taking its values in ${\cal
X}_1 \times ... \times {\cal X}_p = {\cal X}$, where ${\cal X}$ is defined as
the input space. Similarly, let us define as $y \in {\cal Y}$ the value of the
output variable $Y$, where ${\cal Y}$ is defined as the output space. By
definition, both the input and the output spaces are assumed to respectively
contain all possible input vectors and all possible output values. Let
us also note that input variables are sometimes known as {\it features}, input
vectors as {\it objects}, {\it examples} or {\it samples} and the output
variable as {\it target}.

In a typical supervised learning task, past observations are summarized by a
{\it learning set}. It consists in a set of observed input vectors together
with their actual output value. Formally, we define a learning set as follows:

\begin{definition}
A \emph{learning set} ${\cal L}$ is a set of $N$
pairs of input vectors and output values $(\mathbf{x}_1, y_1), ...,
(\mathbf{x}_N, y_N)$, where $\mathbf{x}_i \in {\cal X}$ and $y_i \in {\cal Y}$.
\end{definition}

Among variables that define the problem, we distinguish between two general
types. The former correspond to quantitative variables whose values are integer
or real numbers, such as age or blood pressure. The latter correspond to
qualitative variables whose values are symbolic, such as gender or condition.
Formally, we define them as follows:

\begin{definition}
A variable $X_j$ is \emph{numerical} or \emph{ordered} if ${\cal X}_j$ is a
totally ordered set.
\end{definition}

\begin{definition}
A variable $X_j$ is \emph{categorical} if ${\cal X}_j$ is a finite set of values,
without any natural order.
\end{definition}

Equivalently, a set of $p$-input vectors $\mathbf{x}_i$ (for $i=1, ..., N$) can
be denoted by a $N\times p$ matrix $\mathbf{X}$, whose rows $i=1, ..., N$
correspond to input vectors $\mathbf{x}_i$ and columns $j=1, ..., p$ to input
variables $X_j$. Similarly, the corresponding output values can be written as a
vector $\mathbf{y}=(y_1, ..., y_N)$.

\begin{remark}{Data representation}
\todo{}
\end{remark}

In this framework, the supervised learning task can be stated as learning a
model, or function, ${\cal X} \mapsto {\cal Y}$ from a learning set ${\cal
L}=(\mathbf{X}, \mathbf{y})$. In particular, the goal of the learning task is
to find a model such that its predictions $\hat{Y}$ of the output variable $Y$
are as good as possible. If $Y$ is a categorical variable then the learning
task is a classification problem. If $Y$ is numerical variable, then learning
task is a regression problem. Without loss of generality, the resulting models
can be defined as follows:

\begin{definition}
A \emph{classifier} or \emph{classification rule} is a function ${\cal X}
\mapsto {\cal Y}$, where ${\cal Y}$ is a finite set of classes denoted $\{1, 2, ..., J\}$.
\end{definition}

\begin{definition}
A \emph{regressor} is a function ${\cal X} \mapsto {\cal Y}$, where ${\cal Y}=\mathbb{R}$.
\end{definition}

\begin{remark}{Estimator interface}
\todo{}
\end{remark}


    % { API = array }
    % - Data => variables (types), notation, etc
    % - ML tasks, focus on supervised learning
    %     - Classification regression




\section{Estimating performance}
    % { API = score }
    % - train/test accuracy => underfitting/overfitting
    % - cv accuracy
    % - metrics
    % - bayes error => jusqu'o√π?


\section{Classes of estimators}
    % { API = fit, predict }
    % - Describe popular algorithms (trees, knn, linear models)
