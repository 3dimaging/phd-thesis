\chapter{Background}\label{ch:background}

\section{Learning from data}

In the examples introduced in Chapter~\ref{ch:introduction}, the objective
which is sought is to find a systematic way of predicting a phenomenon given a
set of measurements. In machine learning terms, this goal is formulated as the
{\it supervised learning} task of infering a model that predicts the value of
an output variable based on the observed values of input variables. In
medicine for instance, the goal is to find a decision rule (i.e., a model) for
predicting the condition of a patient (i.e., the output value) given a set of
measurements such as age, sex, blood pressure or history (i.e., the input
values).

To give a more precise formulation, let us arrange the set of measurements in a
pre-assigned order, i.e., take the input values to be $x_1, x_2, ..., x_p$,
where $x_i \in {\cal X}_i$ (for $i = 1, ..., p$) corresponds to the value of
the input variable $X_i$. Together, the input values $(x_1, x_2, ..., x_p)$
form a $p$-dimensional input vector $\mathbf{x}$ taking its values in ${\cal
X}_1 \times ... \times {\cal X}_p = {\cal X}$, where ${\cal X}$ is defined as
the input space. Similarly, let us define as $y \in {\cal Y}$ the value of the
output variable $Y$, where ${\cal Y}$ is defined as the output space. By
definition, both the input and the output spaces are assumed to respectively
contain all possible input vectors and all possible output values. Finally, let us also
note that in the literature, input variables are sometimes known as {\it features},
input vectors as {\it cases}, {\it observations} or {\it samples} and the
output variable as {\it target}.

In a typical supervised learning task, past observations are summarized by a
{\it learning sample}. It consists in a set of observed input
vectors together with their actual output value. Formally, we define a learning
sample as follows:

\begin{definition}
A \emph{learning sample} ${\cal L}$ is a set of $N$
pairs of input vectors and output values $(\mathbf{x}_1, y_1), ...,
(\mathbf{x}_N, y_N)$, where $\mathbf{x}_n \in {\cal X}$ and $y_n \in {\cal Y}$.
\end{definition}


% def variable catégorique, numériques
%

    % { API = array }
    % - Data => variables (types), notation, etc
    % - ML tasks, focus on supervised learning
    %     - Classification regression


\section{Building estimators}
    % { API = fit, predict }
    % - Describe popular algorithms (trees, knn, linear models)


\section{Estimating performance}
    % { API = score }
    % - train/test accuracy => underfitting/overfitting
    % - cv accuracy
    % - metrics
    % - bayes error => jusqu'où?
