\chapter{Background}\label{ch:background}

\section{Learning from data}

In the examples introduced in Chapter~\ref{ch:introduction}, the objective
which is sought is to find a systematic way of predicting a phenomenon given a
set of measurements. In machine learning terms, this goal is formulated as the
{\it supervised learning} task of infering from collected data a model that
predicts the value of an output variable based on the observed values of input
variables. As such, finding an appropriate model is based on the assumption
that the output variable does not take its value at random and that there
exists a relation between the inputs and the output. In medicine for instance,
the goal is to find a decision rule (i.e., a model) from a set of past cases
(i.e., the collected data) for predicting the condition of an incoming patient
(i.e., the output value) given a set of measurements such as age, sex, blood
pressure or history (i.e., the input values).

To give a more precise formulation, let us arrange the set of measurements on a
case in a pre-assigned order, i.e., take the input values to be $x_1, x_2, ...,
x_p$, where $x_j \in {\cal X}_j$ (for $j = 1, ..., p$) corresponds to the value
of the input variable $X_j$. Together, the input values $(x_1, x_2, ..., x_p)$
form a $p$-dimensional input vector $\mathbf{x}$ taking its values in ${\cal
X}_1 \times ... \times {\cal X}_p = {\cal X}$, where ${\cal X}$ is defined as
the input space. Similarly, let us define as $y \in {\cal Y}$ the value of the
output variable $Y$, where ${\cal Y}$ is defined as the output
space\footnote{Unless stated otherwise, supervised learning is reduced to the
prediction of a \textit{single} output variable. More generally however, this
framework can be defined as the prediction of one or several output variables.}.
By definition, both the input and the output spaces are assumed to respectively
contain all possible input vectors and all possible output values. Note that
input variables are sometimes known as {\it features}, input vectors as {\it
objects}, {\it examples} or {\it samples} and the output variable as {\it
target}.

Among variables that define the problem, we distinguish between two general
types. The former correspond to quantitative variables whose values are integer
or real numbers, such as age or blood pressure. The latter correspond to
qualitative variables whose values are symbolic, such as gender or condition.
Formally, we define them as follows:

\begin{definition}
A variable $X_j$ is \emph{numerical} or \emph{ordered} if ${\cal X}_j$ is a
totally ordered set.
\end{definition}

\begin{definition}
A variable $X_j$ is \emph{categorical} if ${\cal X}_j$ is a finite set of values,
without any natural order.
\end{definition}

In a typical supervised learning task, past observations are summarized by a
dataset called {\it learning set}. It consists in a set of observed input
vectors together with their actual output value and formally defined as
follows:

\begin{definition}
A \emph{learning set} ${\cal L}$ is a set of $N$
pairs of input vectors and output values $(\mathbf{x}_1, y_1), ...,
(\mathbf{x}_N, y_N)$, where $\mathbf{x}_i \in {\cal X}$ and $y_i \in {\cal Y}$.
\end{definition}

Equivalently, a set of $p$-input vectors $\mathbf{x}_i$ (for $i=1, ..., N$) can
be denoted by a $N\times p$ matrix $\mathbf{X}$, whose rows $i=1, ..., N$
correspond to input vectors $\mathbf{x}_i$ and columns $j=1, ..., p$ to input
variables $X_j$. Similarly, the corresponding output values can be written as a
vector $\mathbf{y}=(y_1, ..., y_N)$.

\begin{remark}{Data representation}
For optimal implementations of machine learning algorithms, data needs to
represented using structures which allows for high-performance numerical
computation. In this work, code snippets are described under  that assumption
that data is represented using a data structure similar to a NumPy
array~\citep{vanderwalt:2011}.

A NumPy array is basically a multidimensional uniform collection of values, all
of the same type and organized in a given shape. For instance, a matrix
$\mathbf{X}$ can be represented as a 2-dimensional NumPy array of shape $N
\times p$ that contains numbers (e.g., floating point values or integers). This
structure allows for random access in constant time, vectorized high-level
operations and efficient memory usage.

Additionally, using a data representation which is close to the matrix
formulation, like NumPy arrays, makes it possible to write implementations that
are close to their original textbook formulation, thereby making them easier to
understand and maintain. \end{remark}

In this framework, the supervised learning task can be stated as learning a
function $\varphi: {\cal X} \mapsto {\cal Y}$ from a learning set ${\cal
L}=(\mathbf{X}, \mathbf{y})$. In particular, the goal of the learning task is
to find a model such that its predictions $\varphi(\mathbf{x})$, also denoted
by the variable $\hat{Y}$, are as good as possible. If $Y$ is a categorical
variable then the learning task is a classification problem. If $Y$ is
numerical variable, then learning task is a regression problem. Without loss of
generality, the resulting models, or \textit{estimators}, can be defined as
follows:

\begin{definition}
A \emph{classifier} or \emph{classification rule} is a function $\varphi: {\cal X}
\mapsto {\cal Y}$, where ${\cal Y}$ is a finite set of classes denoted $\{1, 2, ..., J\}$.
\end{definition}

\begin{definition}
A \emph{regressor} is a function $\varphi: {\cal X} \mapsto {\cal Y}$, where ${\cal Y}=\mathbb{R}$.
\end{definition}

\begin{remark}{Estimator interface}
We follow in this work the API conventions proposed by~\citet{buitinck:2013}.
In particular, learning algorithms are described as estimators implementing the
following interface:

\begin{itemize}
\item[-] Hyper-parameters of an algorithm are all passed to the constructor of the
estimator. The constructor does not see any actual data. All it does
is to attach hyper-parameters values as public attributes to the estimator object.
\item[-] Learning is performed in a \texttt{fit} method. This method is called with
a learning set (e.g., supplied as two arrays \texttt{X\_train} and \texttt{y\_train}). Its
task is to run a learning algorithm and to determine model-specific parameters
from the data. The \texttt{fit} method always returns the estimator object
it was called on, which now serves as a model and can be used to make predictions.
\item[-] Predictions are performed through a \texttt{predict} method, taking
as input an array \texttt{X\_test} and producing as output the predictions for
\texttt{X\_test} based on the learned parameters. In the case of classification,
this method returns labels from ${\cal Y} = \{1, 2, ..., J\}$. In the case of regression,
it returns numerical values from ${\cal Y} = \mathbb{R}$.
\end{itemize}

With this API, a typical supervised learning task is therefore performed as follows:

\vskip0.3cm
\begin{pythoncode}
# Instantiate and set hyper-parameters
clf = DecisionTreeClassifier(max_depth=5)
# Learn a model from data
clf.fit(X_train, y_train)
# Make predictions on new data
y_hat = clf.predict(X_test)
\end{pythoncode}
\end{remark}


\section{Performance evaluation}

In the statistical sense, input and output variables $X_1, ..., X_p$ and $Y$
are \textit{random variables} taking jointly their values from ${\cal X}
\times {\cal Y}$ with respect to the joint probability distribution $P(X, Y)$,
where $X$ denotes the random vector $(X_1, ..., X_p)$. That is,
$P(X=\mathbf{x}, Y=y)$ is the probability of drawing the couple $(\mathbf{x},
y)$ at random from ${\cal X} \times {\cal Y}$.

Accordingly, learning from ${\cal L}$ a model $\varphi$ whose predictions are as good as
possible can be defined as finding a model $\varphi$ which minimizes its
expected\footnote{$\mathbb{E}_X \{f(X)\}$ denotes the expected value of $f(x)$
(for $x \in {\cal X}$) with respect to the probability distribution of the
random variable $X$. It is defined as $$\mathbb{E}_X \{f(X)\} = \sum_{x \in {\cal
X}} P(X=x) f(x).$$} prediction error
\begin{equation}\label{eqn:generalization-error}
Err(\varphi) = \mathbb{E}_{X, Y}\{ L(Y, \varphi(X)) \},
\end{equation}
where $L$ is a loss function measuring the discrepancy between its two
arguments~\citep{geurts:2002}. Equation~\ref{eqn:generalization-error} is also
known as the \textit{generalization error} of the model. It basically measures
the prediction error of $\varphi$ over all possible couples $(\mathbf{x}, y)\in
{\cal X}\times{\cal Y}$, including the observed couples from the learning set
${\cal L}$ but also all the \textit{unseen} ones from ${\cal X}\times{\cal Y}
\setminus {\cal L}$. Indeed, the goal is not in fact to make the very-most accurate
predictions over the subset ${\cal L}$ of known data, but rather to learn a model which
is correct and reliable on all possible data.

For classification, the most common loss function is the \textit{zero-one} loss
function\footnote{$1(\text{\textit{condition}})$ denotes the unit function. It
is defined as
$$1(\text{\textit{condition}}) =
\begin{cases}
1 & \text{if \textit{condition} is true}\\
0 & \text{if \textit{condition} is false}
\end{cases}.
$$} $L(Y, \varphi(X)) = 1(Y \neq \varphi(X))$, where all
misclassifications are equally penalized. In this case, the generalization
error of $\varphi$ becomes the probability of misclassification of the model:

\begin{equation}
Err(\varphi) = \mathbb{E}_{X, Y}\{ 1(Y \neq \varphi(X)) \} = P(Y \neq \varphi(X))
\end{equation}

Similarly, for regression, the most used loss function is the \textit{squared
error} loss $L(Y, \varphi(X)) = (Y - \varphi(X))^2$, where large differences
between the true values and the predicted values are penalized more heavily
than small ones. With this loss, the generalization error of the model becomes:
\begin{equation}
Err(\varphi) = \mathbb{E}_{X, Y}\{ (Y - \varphi(X))^2 \}
\end{equation}

\subsection{Estimating $Err(\varphi)$}

In practice, the probability distribution $P(X, Y)$ is usually unknown, making
the direct evaluation of $Err(\varphi)$ infeasible. Equivalently, it is often
not possible to draw additional data, thereby making infeasible the empirical
estimation of $Err(\varphi)$ on a (virtually infinite) set ${\cal L}'$ drawn
independently from ${\cal L}$. In most problems, ${\cal L}$ constitutes the
only data available, on which both the model needs to be learned and its
generalization error estimated.
As reviewed and described by several
authors~\citep{toussaint:1974,nadeau:2003,arlot:2010}, the generalization error
in Equation~\ref{eqn:generalization-error} can however be estimated in several ways.

The first and simplest estimate is the \textit{resubstitution estimate} or \textit{training error}. It
consists in empirically estimating $Err(\varphi)$ on the same data as the
learning set ${\cal L}$ used to build $\varphi$, that is:
\begin{equation}\label{eqn:training-error}
\widehat{Err}(\varphi, {\cal L}) = \frac{1}{N} \sum_{(\mathbf{x_i}, y_i) \in {\cal L}} L(y_i, \varphi(\mathbf{x_i}))
\end{equation}
where $N$ is the size of ${\cal L}$.
In general, the resubstitution error is a poor estimate of
$Err(\varphi)$. In particular, since most machine learning algorithms
aim at precisely minimizing Equation~\ref{eqn:training-error} (either directly
or indirectly), it typically results in an underestimation of the
generalization error.

The second approach is the \textit{test sample estimate} or \textit{test error}. It consists in
dividing the learning set ${\cal L}$ into two disjoint sets ${\cal
L}_\text{train}$ and ${\cal L}_\text{test}$, respectively called
\textit{training set} and \textit{test set}, and then to use each part
respectively for learning the model and estimating its generalization error. If
$\varphi_{{\cal L}_\text{train}}$ is the model built on the training set, then
is test sample estimate is given by:
\begin{equation}\label{eqn:test-error}
\widehat{Err}(\varphi_{{\cal L}_\text{train}}, {\cal L}_\text{test}) = \frac{1}{N_\text{test}} \sum_{(\mathbf{x_i}, y_i) \in {\cal L}_\text{test}} L(y_i, \varphi_{{\cal L}_\text{train}}(\mathbf{x_i}))
\end{equation}
where $N_\text{test}$ is the size of ${\cal L}_\text{test}$.

    % Estimation of Err
        % restitution
        % train/test
            % => overfitting/underfitting
        % cv
    % Score method

\subsection{Residual error and Bayes model}

% Hastie

\subsection{Precision, recall and $F$-measure}

% P, R, F, ROC curve, etc


\section{Classes of estimators}
    % See Pierre thesis
    % { API = fit, predict }
    % - Describe popular algorithms (trees, knn, linear models)
